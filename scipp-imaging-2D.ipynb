{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to start\n",
    "\n",
    "Before starting you must:\n",
    "- Ensure that `scipp` and `mantid` are on your `PYTHONPATH`.\n",
    "- Generate the `config.py` file using `make_config.py`. Refer to the `README.md` or `python make_config.py --help` for information.\n",
    "- Install dependency `fabio`: `conda install fabio` (used for image loading)\n",
    "\n",
    "For `scipp` and `mantid` follow instructions at: https://scipp.readthedocs.io/en/latest/getting-started/installation.html.\n",
    "\n",
    "Converted to use scipp and notebook from [this file](https://git.esss.dk/testbeamline/gp2/blob/1c69213b1124982bbbe762da9c6c6457a49f2a92/reduce.py) by Dimitar Tasev on 2020-01-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some PYTHONPATH sanity checks\n",
    "\n",
    "try:\n",
    "    import scipp\n",
    "    print(\"scipp found\")\n",
    "except ImportError as e:\n",
    "    print(\"scipp is not available in the PYTHONPATH\")\n",
    "    raise e\n",
    "    \n",
    "try:\n",
    "    import mantid\n",
    "    print(\"mantid found\")\n",
    "except ImportError as e:\n",
    "    print(\"mantid is not available in the PYTHONPATH\")\n",
    "    raise e\n",
    "    \n",
    "try:\n",
    "    import config\n",
    "    print(\"config found\")\n",
    "except ImportError as e:\n",
    "    print(\"config is not available. Make sure you have generated it with `make_config.py`.\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Whether or not to do the plotting.\n",
    "do_plots = False\n",
    "\n",
    "# Specify where the data can be found, this should be the root folder\n",
    "# containing the data_GP2 folder.\n",
    "experiment_dir = config.script_root\n",
    "\n",
    "# let's get the process started:\n",
    "tofs_path = os.path.join(experiment_dir, 'data_GP2', 'metadata', 'GP2_BCC_time_values.txt')\n",
    "sample_path = os.path.join(experiment_dir, 'data_GP2', 'Timeslices WFM BBC Steel')\n",
    "ob_path = os.path.join(experiment_dir, 'data_GP2', 'Timeslices WFM Open Beam')\n",
    "instrument_file = os.path.join(experiment_dir, 'IDF', 'V20_Definition_GP2.xml')\n",
    "\n",
    "# defining grouping of 2D detector pixels\n",
    "grouping_number = 3\n",
    "nx_target = grouping_number\n",
    "ny_target = grouping_number\n",
    "\n",
    "# Rebin regions for each of the 5 frames\n",
    "# in the format of [bin-start, bin-end, bin width].\n",
    "# used to crop each one, before stitching them together\n",
    "frame_parameters = [(15167, 23563, 64),\n",
    "                    (24393, 32758, 64),\n",
    "                    (33365, 40708, 64),\n",
    "                    (41410, 48019, 64),\n",
    "                    (49041, 55311, 64),\n",
    "                    (56077, 59872, 64)]\n",
    "\n",
    "# Used to shift the cropped frames so that their bins overlap \n",
    "# before summing them together into a single frame\n",
    "frame_shift_increments = [-6630.0, -2420.0, -2253.0, -2095.0, -1946.0, -1810.0]\n",
    "frame_shifts = [sum(frame_shift_increments[:i + 1]) for i in range(len(frame_shift_increments))]\n",
    "\n",
    "# Used to rebin the summed frame in order to\n",
    "# cut off frames that contain no data\n",
    "rebin_parameters = (8500, 43000, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import fabio\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "import scipp as sc\n",
    "import numpy as np\n",
    "from scipp import Dim\n",
    "\n",
    "from mantid.simpleapi import *\n",
    "from mantid.api import AlgorithmManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "\n",
    "def read_x_values(tof_file):\n",
    "    \"\"\"\n",
    "    Reads the TOF values from the CSV into a list\n",
    "    \"\"\"\n",
    "    tof_values = list()\n",
    "    with open(tof_file) as fh:\n",
    "        csv_reader = csv.reader(fh, delimiter='\\t')\n",
    "        next(csv_reader, None)  # skip header\n",
    "        for row in csv_reader:\n",
    "            tof_values.append(float(row[1]))\n",
    "    return tof_values\n",
    "\n",
    "\n",
    "def _load_tiffs(tiff_dir):\n",
    "    if not os.path.isdir(tiff_dir):\n",
    "        raise RuntimeError(tiff_dir + \" is not directory\")\n",
    "    stack = []\n",
    "    path_length = len(tiff_dir) + 1\n",
    "    filenames = sorted(glob.glob(tiff_dir + \"/*.tiff\"))\n",
    "    nfiles = len(filenames)\n",
    "    count = 0\n",
    "    print(f\"Loading {nfiles} files from '{tiff_dir}'\")\n",
    "    for filename in filenames:\n",
    "        count += 1\n",
    "        print('\\r{0}: Image {1}, of {2}'.format(filename[path_length:], count, nfiles), end=\"\")\n",
    "        img = fabio.open(os.path.join(tiff_dir, filename))\n",
    "        stack.append(np.flipud(img.data))\n",
    "\n",
    "    return np.array(stack)\n",
    "\n",
    "def tiffs_to_variable(tiff_dir):\n",
    "    \"\"\"\n",
    "    Loads all tiff images from the directory into a scipp Variable.\n",
    "    \"\"\"\n",
    "    stack = _load_tiffs(tiff_dir)\n",
    "    data = stack.astype(np.float64).reshape(stack.shape[0], stack.shape[1]*stack.shape[2])\n",
    "    return sc.Variable([Dim.Tof, Dim.Spectrum], \n",
    "                       values=data, variances=data)\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "def stitch(data_array, frame_parameters, rebin_parameters):\n",
    "    \"\"\"\n",
    "    Stitches the 5 different frames data.\n",
    "    \n",
    "    It crops out each frame, then shifts it so that all frames align,\n",
    "    and then rebins to the common bins used for all frames.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "\n",
    "    rebin_params = sc.Variable([Dim.Tof], values=np.arange(*rebin_parameters, dtype=np.float64))\n",
    "    \n",
    "    for i, (slice_bins, shift_parameter) in enumerate(zip(frame_parameters, frame_shifts)):\n",
    "        bins = sc.Variable([Dim.Tof], values=np.arange(*slice_bins, dtype=np.float64))\n",
    "        # Rebins the whole data to crop it to frame bins\n",
    "        rebinned = sc.rebin(data_array, Dim.Tof, bins)\n",
    "        # Shift the frame backwards to make all frames overlap\n",
    "        rebinned.coords[Dim.Tof] += shift_parameter\n",
    "        # Rebin to overarching coordinates so that the frame coordinates align\n",
    "        rebinned = sc.rebin(rebinned, Dim.Tof, rebin_params)\n",
    "\n",
    "        frames.append(rebinned)\n",
    "\n",
    "    for f in frames[1:]:\n",
    "        frames[0] += f\n",
    "\n",
    "    return frames[0]\n",
    "\n",
    "def zero_special_values(values):\n",
    "    np.nan_to_num(values, copy=False)\n",
    "    values[values == sys.float_info.max] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = sc.Dataset()\n",
    "\n",
    "# Load X values from the TOF file\n",
    "ds.coords[Dim.Tof] = sc.Variable([Dim.Tof], unit=sc.units.us, values=read_x_values(tofs_path))\n",
    "ds.coords[Dim.Tof] *= 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data into the dataset\n",
    "ds[\"sample\"] = tiffs_to_variable(sample_path)\n",
    "ds[\"reference\"] = tiffs_to_variable(ob_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sc.plot.plot(sc.sum(ds, Dim.Spectrum)) if do_plots else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adds a coordinate for the spectra\n",
    "ds.coords[Dim.Spectrum] = sc.Variable([Dim.Spectrum], values=np.arange(ds[\"sample\"].shape[1]))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stitched = sc.Dataset(coords={Dim.Tof: sc.Variable([Dim.Tof], values=np.arange(*rebin_parameters, dtype=np.float64))})\n",
    "\n",
    "stitched[\"sample\"] = stitch(ds[\"sample\"], frame_parameters, rebin_parameters)\n",
    "stitched[\"reference\"] = stitch(ds[\"reference\"], frame_parameters, rebin_parameters)\n",
    "\n",
    "stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_detector_groups(nx_original, ny_original, nx_target, ny_target):\n",
    "    element_width_x = nx_original // nx_target\n",
    "    element_width_y = ny_original // ny_target\n",
    "    \n",
    "    # To contain our new spectra mappings\n",
    "    grid = np.zeros((nx_original, ny_original), dtype=np.float64)\n",
    "\n",
    "    for i in range(0, nx_target):\n",
    "        x_start = i * element_width_x\n",
    "        x_end = (i + 1) * element_width_x\n",
    "        \n",
    "        for j in range(0, ny_target):\n",
    "            y_start = j * element_width_y\n",
    "            y_end = (j + 1) * element_width_y\n",
    "\n",
    "            vals = np.full((element_width_x, element_width_y), i + j * nx_target, dtype=np.float64)\n",
    "            grid[x_start:x_end, y_start:y_end] = vals\n",
    "    \n",
    "    return sc.Variable([Dim.Spectrum], values=grid.ravel())\n",
    "\n",
    "\n",
    "stitched.labels[\"detector_mapping\"] = make_detector_groups(324, 324, nx_target, ny_target)\n",
    "stitched.labels[\"detector_mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stitched[\"normalized\"] = stitched[\"sample\"] / stitched[\"reference\"]\n",
    "\n",
    "zero_special_values(stitched[\"normalized\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dm1d = sc.groupby(stitched[\"normalized\"], \"detector_mapping\", Dim.Row)\n",
    "stitched[\"normalized_grpd\"] = dm1d.sum(Dim.Spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the first group\n",
    "sc.plot.plot(sc.sum(stitched[\"normalized_grpd\"], Dim.Row)) if do_plots else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adds the component info needed for converting units\n",
    "sc.compat.mantid.load_component_info(stitched, instrument_file)\n",
    "stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note: this cell is currently a workaround until \n",
    "# https://github.com/scipp/scipp/issues/823 is done.\n",
    "# Then it should be possible to group the positions label directly.\n",
    "\n",
    "# makes the position a DataConstProxy otherwise groupby won't take it\n",
    "stitched[\"position\"] = stitched.labels[\"position\"]\n",
    "dm1d = sc.groupby(stitched[\"position\"], \"detector_mapping\", Dim.Row)\n",
    "position = dm1d.mean(Dim.Spectrum)\n",
    "\n",
    "# can't do stitched.labels[\"position\"] = position because Labels won't take a DataArray\n",
    "# also can't do stitched.labels[\"position\"] = sc.Variable(position) because then sc.convert \n",
    "# thinks stitched.labels[\"position\"] is dimensionless (as it's actually still a DataArray)\n",
    "\n",
    "pos = np.zeros((position.shape[0], 3))\n",
    "for i, val in enumerate(position.values):\n",
    "    pos[i, :] = val\n",
    "\n",
    "# finally add it back!\n",
    "stitched.labels[\"position\"] = sc.Variable(position.dims, pos, unit=sc.units.m, dtype=position.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stitched[\"normalized_wl\"] = sc.neutron.convert(stitched[\"normalized_grpd\"], Dim.Tof, Dim.Wavelength)\n",
    "stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.plot.plot(stitched[\"normalized_wl\"][Dim.Row, 0]) if do_plots else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_coords = stitched[\"normalized_wl\"].coords[stitched[\"normalized_wl\"].dims[0]]\n",
    "x_dim = stitched[\"normalized_wl\"].dims[0]\n",
    "x = x_coords.values\n",
    "\n",
    "# Mantid expects the data in a different shape\n",
    "# which is spectrum as outer-most dimension.\n",
    "y = np.transpose(stitched[\"normalized_wl\"].values)\n",
    "\n",
    "e = np.transpose(stitched[\"normalized_wl\"].variances)\n",
    "\n",
    "ws = sc.compat.mantid.to_workspace_2d(x, y, e, x_dim, instrument_file)\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If you want to save the workspace uncomment this line\n",
    "SaveNexusESS(ws, \"scipp_normalized_wl.nxs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_ds = sc.compat.mantid.fit(ws, \n",
    "                     function='name=LinearBackground,A0=5000,A1=0;name=UserFunction,Formula=h*erfc(a*(x-x0)),h=5000,a=-0.5,x0=4',\n",
    "                    workspace_index=2, start_x=3.6, end_x=4.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.plot.plot(fit_ds[\"workspace\"].value, collapse=Dim.Wavelength)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scipp-mantid] *",
   "language": "python",
   "name": "conda-env-scipp-mantid-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
