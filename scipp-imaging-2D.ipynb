{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to start\n",
    "\n",
    "Before starting you must:\n",
    "- Ensure that `scipp` and `mantid` are on your `PYTHONPATH`.\n",
    "- Generate the `config.py` file using `make_config.py`. Refer to the `README.md` or `python make_config.py --help` for information.\n",
    "- Install dependencies : `conda install fabio tifffile` (used for image handling)\n",
    "\n",
    "For `scipp` and `mantid` follow instructions at: https://scipp.readthedocs.io/en/latest/getting-started/installation.html.\n",
    "\n",
    "Converted to use scipp and notebook from [this file](https://git.esss.dk/testbeamline/gp2/blob/1c69213b1124982bbbe762da9c6c6457a49f2a92/reduce.py) by Dimitar Tasev on 2020-01-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import scipp\n",
    "    print(\"scipp found\")\n",
    "except ImportError as e:\n",
    "    print(\"scipp is not available in the PYTHONPATH\")\n",
    "    raise e\n",
    "    \n",
    "try:\n",
    "    import mantid\n",
    "    print(\"mantid found\")\n",
    "except ImportError as e:\n",
    "    print(\"mantid is not available in the PYTHONPATH\")\n",
    "    raise e\n",
    "    \n",
    "try:\n",
    "    import scippconfig\n",
    "    print(\"scippconfig found\")\n",
    "except ImportError as e:\n",
    "    print(\"scippconfig is not available. Make sure you have generated it with `make_config.py`.\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get everything set up\n",
    "\n",
    "import csv\n",
    "import glob\n",
    "import fabio\n",
    "import os\n",
    "\n",
    "import scipp as sc\n",
    "import numpy as np\n",
    "from scipp import Dim\n",
    "from mantid.simpleapi import SaveNexusESS\n",
    "\n",
    "DATA_DIR_NAME = \"data_GP2\"\n",
    "experiment_dir = scippconfig.script_root\n",
    "data_dir = os.path.join(scippconfig.script_root, DATA_DIR_NAME)\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    raise FileNotFoundError(\"The following data directory does not exist,\"\n",
    "                            f\" check your make_config.py:\\n{data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customisable Options:\n",
    "\n",
    "# Whether or not to do the plotting.\n",
    "do_plots = True\n",
    "\n",
    "# defining grouping of 2D detector pixels\n",
    "grouping_number = 3\n",
    "nx_target = grouping_number\n",
    "ny_target = grouping_number\n",
    "\n",
    "# Rebin regions for each of the 5 frames\n",
    "# in the format of [bin-start, bin-end, bin width].\n",
    "# used to crop each image, before stitching them together\n",
    "frame_parameters = [(15167, 23563, 64),\n",
    "                    (24393, 32758, 64),\n",
    "                    (33365, 40708, 64),\n",
    "                    (41410, 48019, 64),\n",
    "                    (49041, 55311, 64),\n",
    "                    (56077, 59872, 64)]\n",
    "\n",
    "# Used to shift the cropped frames so that their bins overlap \n",
    "# before summing them together into a single frame\n",
    "frame_shift_increments = [-6630.0, -2420.0, -2253.0, -2095.0, -1946.0, -1810.0]\n",
    "frame_shifts = [sum(frame_shift_increments[:i + 1]) for i in range(len(frame_shift_increments))]\n",
    "\n",
    "# Used to rebin the summed frame in order to\n",
    "# cut off frames that contain no data\n",
    "rebin_parameters = (8500, 43000, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "def read_x_values(tof_file):\n",
    "    \"\"\"\n",
    "    Reads the TOF values from the CSV into a list\n",
    "    \"\"\"\n",
    "    tof_values = []\n",
    "    with open(tof_file) as fh:\n",
    "        csv_reader = csv.reader(fh, delimiter='\\t')\n",
    "        next(csv_reader, None)  # skip header\n",
    "        for row in csv_reader:\n",
    "            tof_values.append(float(row[1]))\n",
    "    return tof_values\n",
    "\n",
    "\n",
    "def _load_tiffs(tiff_dir):\n",
    "    if not os.path.isdir(tiff_dir):\n",
    "        raise RuntimeError(tiff_dir + \" is not directory\")\n",
    "    stack = []\n",
    "    path_length = len(tiff_dir) + 1\n",
    "    filenames = sorted(glob.glob(tiff_dir + \"/*.tiff\"))\n",
    "    nfiles = len(filenames)\n",
    "    count = 0\n",
    "    print(f\"Loading {nfiles} files from '{tiff_dir}'\")\n",
    "    for filename in filenames:\n",
    "        count += 1\n",
    "        print('\\r{0}: Image {1}, of {2}'.format(filename[path_length:], count, nfiles), end=\"\")\n",
    "        img = fabio.open(os.path.join(tiff_dir, filename))\n",
    "        stack.append(np.flipud(img.data))\n",
    "\n",
    "    return np.array(stack)\n",
    "\n",
    "def tiffs_to_variable(tiff_dir):\n",
    "    \"\"\"\n",
    "    Loads all tiff images from the directory into a scipp Variable.\n",
    "    \"\"\"\n",
    "    stack = _load_tiffs(tiff_dir)\n",
    "    data = stack.astype(np.float64).reshape(stack.shape[0], stack.shape[1]*stack.shape[2])\n",
    "    return sc.Variable([Dim.Tof, Dim.Spectrum], \n",
    "                       values=data, variances=data)\n",
    "\n",
    "def stitch(data_array, frame_parameters, rebin_parameters):\n",
    "    \"\"\"\n",
    "    Stitches the 5 different frames data.\n",
    "    \n",
    "    It crops out each frame, then shifts it so that all frames align,\n",
    "    and then rebins to the common bins used for all frames.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "\n",
    "    rebin_params = sc.Variable([Dim.Tof], values=np.arange(*rebin_parameters, dtype=np.float64))\n",
    "    \n",
    "    for i, (slice_bins, shift_parameter) in enumerate(zip(frame_parameters, frame_shifts)):\n",
    "        bins = sc.Variable([Dim.Tof], values=np.arange(*slice_bins, dtype=np.float64))\n",
    "        # Rebins the whole data to crop it to frame bins\n",
    "        rebinned = sc.rebin(data_array, Dim.Tof, bins)\n",
    "        # Shift the frame backwards to make all frames overlap\n",
    "        rebinned.coords[Dim.Tof] += shift_parameter\n",
    "        # Rebin to overarching coordinates so that the frame coordinates align\n",
    "        rebinned = sc.rebin(rebinned, Dim.Tof, rebin_params)\n",
    "\n",
    "        frames.append(rebinned)\n",
    "\n",
    "    for f in frames[1:]:\n",
    "        frames[0] += f\n",
    "\n",
    "    return frames[0]\n",
    "\n",
    "def make_detector_groups(nx_original, ny_original, nx_target, ny_target):\n",
    "    element_width_x = nx_original // nx_target\n",
    "    element_width_y = ny_original // ny_target\n",
    "    \n",
    "    # To contain our new spectra mappings\n",
    "    grid = np.zeros((nx_original, ny_original), dtype=np.float64)\n",
    "\n",
    "    for i in range(0, nx_target):\n",
    "        x_start = i * element_width_x\n",
    "        x_end = (i + 1) * element_width_x\n",
    "        \n",
    "        for j in range(0, ny_target):\n",
    "            y_start = j * element_width_y\n",
    "            y_end = (j + 1) * element_width_y\n",
    "\n",
    "            vals = np.full((element_width_x, element_width_y), i + j * nx_target, dtype=np.float64)\n",
    "            grid[x_start:x_end, y_start:y_end] = vals\n",
    "    \n",
    "    return sc.Variable([Dim.Spectrum], values=grid.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's get the process started:\n",
    "tofs_path = os.path.join(data_dir, 'metadata', 'GP2_BCC_time_values.txt')\n",
    "sample_path = os.path.join(data_dir, 'Timeslices WFM BBC Steel')\n",
    "ob_path = os.path.join(data_dir, 'Timeslices WFM Open Beam')\n",
    "instrument_file = os.path.join(experiment_dir, 'IDF', 'V20_Definition_GP2.xml')\n",
    "\n",
    "ds = sc.Dataset()\n",
    "\n",
    "# Load X values from the TOF file\n",
    "ds.coords[Dim.Tof] = sc.Variable([Dim.Tof], unit=sc.units.us, values=read_x_values(tofs_path))\n",
    "ds.coords[Dim.Tof] *= 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data into the dataset\n",
    "ds[\"sample\"] = tiffs_to_variable(sample_path)\n",
    "ds[\"reference\"] = tiffs_to_variable(ob_path)\n",
    "\n",
    "sc.plot.plot(sc.sum(ds, Dim.Spectrum)) if do_plots else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adds a coordinate for the spectra\n",
    "ds.coords[Dim.Spectrum] = sc.Variable([Dim.Spectrum], values=np.arange(ds[\"sample\"].shape[1]))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stitched = sc.Dataset(coords={Dim.Tof: sc.Variable([Dim.Tof], values=np.arange(*rebin_parameters, dtype=np.float64))})\n",
    "\n",
    "stitched[\"sample\"] = stitch(ds[\"sample\"], frame_parameters, rebin_parameters)\n",
    "stitched[\"reference\"] = stitch(ds[\"reference\"], frame_parameters, rebin_parameters)\n",
    "\n",
    "sc.plot.plot(sc.sum(stitched, Dim.Spectrum)) if do_plots else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stitched.coords[\"detector_mapping\"] = make_detector_groups(324, 324, nx_target, ny_target)\n",
    "stitched.coords[\"detector_mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stitched[\"normalized\"] = stitched[\"sample\"] / stitched[\"reference\"]\n",
    "replacement=sc.Variable(value=0.0, variance=0.0)\n",
    "kwargs = {\"nan\" : replacement, \"posinf\" : replacement, \"neginf\" : replacement}\n",
    "sc.nan_to_num(stitched[\"normalized\"].data, out=stitched[\"normalized\"].data, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dm1d = sc.groupby(stitched[\"normalized\"], \"detector_mapping\")\n",
    "grouped = sc.Dataset()\n",
    "grouped[\"normalized_grpd\"] = dm1d.sum(Dim.Spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the first group\n",
    "grouped\n",
    "sc.plot.plot(grouped[\"normalized_grpd\"]['detector_mapping', 0]) if do_plots else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adds the component info needed for converting units\n",
    "sc.compat.mantid.load_component_info(stitched, instrument_file)\n",
    "\n",
    "grouped.coords[\"source_position\"] = stitched.coords[\"source_position\"]\n",
    "grouped.coords[\"sample_position\"] = stitched.coords[\"sample_position\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note: this cell is currently a workaround until \n",
    "# https://github.com/scipp/scipp/issues/823 is done.\n",
    "# Then it should be possible to group the positions label directly.\n",
    "\n",
    "# makes the position a DataConstProxy otherwise groupby won't take it\n",
    "stitched[\"position\"] = stitched.coords[\"position\"]\n",
    "dm1d = sc.groupby(stitched[\"position\"], \"detector_mapping\")\n",
    "position = dm1d.mean(Dim.Spectrum)\n",
    "\n",
    "# can't do stitched.labels[\"position\"] = position because Labels won't take a DataArray\n",
    "# also can't do stitched.labels[\"position\"] = sc.Variable(position) because then sc.convert \n",
    "# thinks stitched.labels[\"position\"] is dimensionless (as it's actually still a DataArray)\n",
    "\n",
    "pos = np.zeros((position.shape[0], 3))\n",
    "for i, val in enumerate(position.values):\n",
    "    pos[i, :] = val\n",
    "\n",
    "# finally add it back!\n",
    "grouped.coords[\"position\"] = sc.Variable(position.dims, pos, unit=sc.units.m, dtype=position.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped[\"normalized_wl\"] = sc.neutron.convert(grouped[\"normalized_grpd\"], Dim.Tof, Dim.Wavelength)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.plot.plot(grouped[\"normalized_wl\"][\"detector_mapping\", 0]) if do_plots else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_coords = grouped[\"normalized_wl\"].coords[\"wavelength\"]\n",
    "x_dim = grouped[\"normalized_wl\"].dims[0]\n",
    "x = x_coords.values\n",
    "\n",
    "# Mantid expects the data in a different shape\n",
    "# which is spectrum as outer-most dimension.\n",
    "y = np.transpose(grouped[\"normalized_wl\"].values)\n",
    "e = np.transpose(grouped[\"normalized_wl\"].variances)\n",
    "\n",
    "ws = sc.compat.mantid.to_workspace_2d(x, y, e, str(x_dim), instrument_file)\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If you want to save the workspace uncomment this line\n",
    "SaveNexusESS(ws, \"scipp_normalized_wl.nxs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_ds = sc.compat.mantid.fit(ws, \n",
    "                    function='name=LinearBackground,A0=5000,A1=0;name=UserFunction,Formula=h*erfc(a*(x-x0)),h=5000,a=-0.5,x0=4',\n",
    "                    workspace_index=2, start_x=3.6, end_x=4.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_handle = sc.plot.plot(fit_ds[\"workspace\"].value)\n",
    "plot_handle = sc.plot.plot(fit_ds[\"workspace\"].value, collapse=Dim.Wavelength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tiled = [fit_ds[\"workspace\"].value, fit_ds[\"workspace\"].value]\n",
    "plots = sc.plot.tiled_plot(tiled, collapse=Dim.Wavelength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plots = sc.plot.tiled_plot(tiled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}