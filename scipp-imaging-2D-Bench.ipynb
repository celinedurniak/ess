{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to start\n",
    "\n",
    "Before starting you must:\n",
    "- Ensure that `scipp` and `mantid` are on your `PYTHONPATH`.\n",
    "- Generate the `config.py` file using `make_config.py`. Refer to the `README.md` or `python make_config.py --help` for information.\n",
    "- Install dependencies : `conda install fabio tifffile` (used for image handling)\n",
    "\n",
    "For `scipp` and `mantid` follow instructions at: https://scipp.readthedocs.io/en/latest/getting-started/installation.html.\n",
    "\n",
    "Converted to use scipp and notebook from [this file](https://git.esss.dk/testbeamline/gp2/blob/1c69213b1124982bbbe762da9c6c6457a49f2a92/reduce.py) by Dimitar Tasev on 2020-01-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "try:\n",
    "    import scipp\n",
    "    print(\"scipp found\")\n",
    "except ImportError as e:\n",
    "    print(\"scipp is not available in the PYTHONPATH\")\n",
    "    raise e\n",
    "\n",
    "try:\n",
    "    import mantid\n",
    "    print(\"mantid found\")\n",
    "except ImportError as e:\n",
    "    print(\"mantid is not available in the PYTHONPATH\")\n",
    "    raise e\n",
    "\n",
    "try:\n",
    "    import scippconfig\n",
    "    print(\"scippconfig found\")\n",
    "except ImportError as e:\n",
    "    print(\"scippconfig is not available. Make sure you have generated it with `make_config.py`.\")\n",
    "    raise e\n",
    "\n",
    "try:\n",
    "    import wfm_stitching\n",
    "    print(\"Legacy wfm stitching found\")\n",
    "except ImportError as e:\n",
    "    print(\"wfm_stitching is required to benchmark Mantid\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import fabio\n",
    "import os\n",
    "\n",
    "import scipp as sc\n",
    "import numpy as np\n",
    "from scipp import Dim\n",
    "from enum import Enum\n",
    "from mantid.api import AlgorithmManager, AnalysisDataService\n",
    "from mantid.simpleapi import (ConvertUnits, Divide, GroupDetectors,\n",
    "                              ReplaceSpecialValues, SaveNexus, Scale, ScaleX,\n",
    "                              SumSpectra, mtd, SaveNexusESS)\n",
    "\n",
    "import timeit\n",
    "\n",
    "DATA_DIR_NAME = \"data_GP2\"\n",
    "experiment_dir = scippconfig.script_root\n",
    "data_dir = os.path.join(scippconfig.script_root, DATA_DIR_NAME)\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    raise FileNotFoundError(\"The following data directory does not exist,\"\n",
    "                            f\" check your make_config.py:\\n{data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customisable Options:\n",
    "class BenchSelection(Enum):\n",
    "    Both = 0\n",
    "    Mantid = 1\n",
    "    Scipp = 2\n",
    "    \n",
    "bench_selection = BenchSelection.Scipp\n",
    "\n",
    "# defining grouping of 2D detector pixels\n",
    "grouping_number = 3\n",
    "nx_target = grouping_number\n",
    "ny_target = grouping_number\n",
    "\n",
    "# Rebin regions for each of the 5 frames\n",
    "# in the format of [bin-start, bin-end, bin width].\n",
    "# used to crop each image, before stitching them together\n",
    "frame_parameters = [(15167, 23563, 64),\n",
    "                    (24393, 32758, 64),\n",
    "                    (33365, 40708, 64),\n",
    "                    (41410, 48019, 64),\n",
    "                    (49041, 55311, 64),\n",
    "                    (56077, 59872, 64)]\n",
    "\n",
    "# Repack into min, width, max for Mantid\n",
    "mantid_frame_parameters = [(p[0], p[2], p[1]) for p in frame_parameters]\n",
    "\n",
    "# Used to shift the cropped frames so that their bins overlap\n",
    "# before summing them together into a single frame\n",
    "frame_shift_increments = [-6630.0, -2420.0, -2253.0, -2095.0, -1946.0, -1810.0]\n",
    "frame_shifts = [sum(frame_shift_increments[:i + 1]) for i in range(len(frame_shift_increments))]\n",
    "\n",
    "# Used to rebin the summed frame in order to\n",
    "# cut off frames that contain no data\n",
    "rebin_parameters = (8500, 43000, 64)\n",
    "mantid_rebin_parameters = \"8500,64,43000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCIPP Helper functions\n",
    "def read_x_values(tof_file):\n",
    "    \"\"\"\n",
    "    Reads the TOF values from the CSV into a list\n",
    "    \"\"\"\n",
    "    tof_values = []\n",
    "    with open(tof_file) as fh:\n",
    "        csv_reader = csv.reader(fh, delimiter='\\t')\n",
    "        next(csv_reader, None)  # skip header\n",
    "        for row in csv_reader:\n",
    "            tof_values.append(float(row[1]))\n",
    "    return tof_values\n",
    "\n",
    "\n",
    "def load_tiffs(tiff_dir):\n",
    "    if not os.path.isdir(tiff_dir):\n",
    "        raise RuntimeError(tiff_dir + \" is not directory\")\n",
    "    stack = []\n",
    "    path_length = len(tiff_dir) + 1\n",
    "    filenames = sorted(glob.glob(tiff_dir + \"/*.tiff\"))\n",
    "    nfiles = len(filenames)\n",
    "    count = 0\n",
    "    print(f\"Loading {nfiles} files from '{tiff_dir}'\")\n",
    "    for filename in filenames:\n",
    "        count += 1\n",
    "        print('\\r{0}: Image {1}, of {2}'.format(filename[path_length:], count, nfiles), end=\"\")\n",
    "        img = fabio.open(os.path.join(tiff_dir, filename))\n",
    "        stack.append(np.flipud(img.data))\n",
    "\n",
    "    return np.array(stack)\n",
    "\n",
    "def tiffs_to_variable(tiff_dir):\n",
    "    \"\"\"\n",
    "    Loads all tiff images from the directory into a scipp Variable.\n",
    "    \"\"\"\n",
    "    stack = load_tiffs(tiff_dir)\n",
    "    data = stack.astype(np.float64).reshape(stack.shape[0], stack.shape[1]*stack.shape[2])\n",
    "    return sc.Variable([Dim.Tof, Dim.Spectrum],\n",
    "                       values=data, variances=data)\n",
    "\n",
    "def stitch(data_array, frame_parameters, rebin_parameters):\n",
    "    \"\"\"\n",
    "    Stitches the 5 different frames data.\n",
    "\n",
    "    It crops out each frame, then shifts it so that all frames align,\n",
    "    and then rebins to the common bins used for all frames.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "\n",
    "    rebin_params = sc.Variable([Dim.Tof], values=np.arange(*rebin_parameters, dtype=np.float64))\n",
    "\n",
    "    for i, (slice_bins, shift_parameter) in enumerate(zip(frame_parameters, frame_shifts)):\n",
    "        bins = sc.Variable([Dim.Tof], values=np.arange(*slice_bins, dtype=np.float64))\n",
    "        # Rebins the whole data to crop it to frame bins\n",
    "        rebinned = sc.rebin(data_array, Dim.Tof, bins)\n",
    "        # Shift the frame backwards to make all frames overlap\n",
    "        rebinned.coords[Dim.Tof] += shift_parameter\n",
    "        # Rebin to overarching coordinates so that the frame coordinates align\n",
    "        rebinned = sc.rebin(rebinned, Dim.Tof, rebin_params)\n",
    "\n",
    "        frames.append(rebinned)\n",
    "\n",
    "    for f in frames[1:]:\n",
    "        frames[0] += f\n",
    "\n",
    "    return frames[0]\n",
    "\n",
    "def make_detector_groups(nx_original, ny_original, nx_target, ny_target):\n",
    "    element_width_x = nx_original // nx_target\n",
    "    element_width_y = ny_original // ny_target\n",
    "\n",
    "    # To contain our new spectra mappings\n",
    "    grid = np.zeros((nx_original, ny_original), dtype=np.float64)\n",
    "\n",
    "    for i in range(0, nx_target):\n",
    "        x_start = i * element_width_x\n",
    "        x_end = (i + 1) * element_width_x\n",
    "\n",
    "        for j in range(0, ny_target):\n",
    "            y_start = j * element_width_y\n",
    "            y_end = (j + 1) * element_width_y\n",
    "\n",
    "            vals = np.full((element_width_x, element_width_y), i + j * nx_target, dtype=np.float64)\n",
    "            grid[x_start:x_end, y_start:y_end] = vals\n",
    "\n",
    "    return sc.Variable([Dim.Spectrum], values=grid.ravel())\n",
    "\n",
    "def mantid_x_values(tof_file):\n",
    "    tof_values = list()\n",
    "    with open(tof_file) as fh:\n",
    "        csv_reader = csv.reader(fh, delimiter='\\t')\n",
    "        next(csv_reader, None)  # skip header\n",
    "        for row in csv_reader:\n",
    "            tof_values.append(float(row[1]))\n",
    "    return tof_values\n",
    "\n",
    "\n",
    "def mantid_mask_in_place(ws_name):\n",
    "    spec_info = mtd[ws_name].spectrumInfo()\n",
    "    for i, item in enumerate(spec_info):\n",
    "        y = item.position.Y()\n",
    "        if y > 0.00406 or y < -0.00126:\n",
    "            spec_info.setMasked(i, True)\n",
    "\n",
    "\n",
    "def mantid_tiffs_to_workspace(tiff_dir, x_values, ws_name):\n",
    "    if not os.path.isdir(tiff_dir):\n",
    "        raise RuntimeError(tiff_dir + \" is not directory\")\n",
    "    stack = list()\n",
    "    path_length = len(tiff_dir) + 1\n",
    "    filenames = sorted(glob.glob(tiff_dir + \"/*.tiff\"))\n",
    "    nfiles = len(filenames)\n",
    "    count = 0\n",
    "    print(f\"Loading {nfiles} files from '{tiff_dir}' for '{ws_name}'\")\n",
    "    for filename in filenames:\n",
    "        count += 1\n",
    "        print('\\r{0}: Image {1}, of {2}'.format(filename[path_length:], count, nfiles), end=\"\")\n",
    "        img = fabio.open(os.path.join(tiff_dir, filename))\n",
    "        stack.append(np.flipud(img.data))\n",
    "\n",
    "    data = np.dstack(stack)\n",
    "    image_dims = data.shape\n",
    "\n",
    "    # Use AlgorithmManager and create as child for speed. Avoids history creation\n",
    "    alg = AlgorithmManager.create(\"CreateWorkspace\")\n",
    "    alg.setChild(True)\n",
    "    alg.initialize()\n",
    "    alg.setProperty('DataX', x_values)\n",
    "    alg.setProperty('DataY', data)\n",
    "    alg.setProperty('DataE', np.sqrt(data))\n",
    "    alg.setProperty('NSpec', image_dims[0]*image_dims[1])\n",
    "    alg.setProperty('OutputWorkspace', ws_name)\n",
    "    alg.setProperty('UnitX', 'TOF')\n",
    "    alg.execute()\n",
    "    ws = alg.getProperty('OutputWorkspace').value\n",
    "    mtd.addOrReplace(ws_name, ws)\n",
    "    return ws\n",
    "\n",
    "\n",
    "def mantid_make_map_file(destination, nx_original, ny_original, nx_target, ny_target, start_spectrum_id=1, grid=None):\n",
    "    if not nx_original % nx_target == 0:\n",
    "        raise RuntimeError('Cannot have fractional re-gridding in x')\n",
    "    if not ny_original % ny_target == 0:\n",
    "        raise RuntimeError('Cannot have fractional re-gridding in y')\n",
    "\n",
    "    # Make a grid that models the spectrum ids in our original 2d_detector.\n",
    "    # Must be a continguous range. We use this for slicing\n",
    "    if not grid:\n",
    "        grid = np.arange(start_spectrum_id, (nx_original*ny_original) +\n",
    "                         start_spectrum_id).reshape((nx_original, ny_original))\n",
    "    element_width_x = nx_original/nx_target\n",
    "    element_width_y = ny_original/ny_target\n",
    "\n",
    "    groups = list()  # To contain our new spectra mappings\n",
    "    for i in range(0, nx_target):\n",
    "        startx = int(i * element_width_x)\n",
    "        endx = int(startx + element_width_x)\n",
    "        for j in range(0, ny_target):\n",
    "            starty = int(j * element_width_y)\n",
    "            endy = int(starty + element_width_y)\n",
    "            # Create slices for each block in our re-gridded region\n",
    "            groups.append(grid[starty:endy, startx:endx].flatten())\n",
    "\n",
    "    with open(destination, 'w') as fh:\n",
    "        # See http://docs.mantidproject.org/nightly/algorithms/GroupDetectors-v2.html#usage\n",
    "        fh.write('{}\\n'.format(len(groups)))\n",
    "        for i, group in enumerate(groups):\n",
    "            fh.write('{}\\n'.format(i+1))\n",
    "            fh.write('{}\\n'.format(len(group)))\n",
    "            fh.write('{}\\n'.format(' '.join(map(str, group))))\n",
    "        return destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TotalTime(object):\n",
    "    scipp_total_time:float = 0\n",
    "    mantid_total_time:float = 0\n",
    "    \n",
    "# A small workaround for the fact floats are immutable types\n",
    "totals = TotalTime()\n",
    "    \n",
    "\n",
    "def _time_f(func):\n",
    "    # We have to wrap time to return anything and not monkey-patch timeit\n",
    "    assert(callable(func))\n",
    "    start = timeit.default_timer()\n",
    "    result = func()\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    elapsed = stop - start\n",
    "    print(f\"\\n Time (s): {elapsed}\")\n",
    "    return elapsed, result\n",
    "\n",
    "def bench_scipp_func(func):\n",
    "    if bench_selection is BenchSelection.Mantid:\n",
    "        return\n",
    "\n",
    "    print(\"\\nScipp: \")\n",
    "    t, result = _time_f(func)\n",
    "    totals.scipp_total_time += t\n",
    "    return result\n",
    "\n",
    "def bench_mantid_func(func):\n",
    "    if bench_selection is BenchSelection.Scipp:\n",
    "        return\n",
    "\n",
    "    print(\"\\nMantid: \")\n",
    "    t, result = _time_f(func)\n",
    "    totals.mantid_total_time += t\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tofs_path = os.path.join(data_dir, 'metadata', 'GP2_BCC_time_values.txt')\n",
    "sample_path = os.path.join(data_dir, 'Timeslices WFM BBC Steel')\n",
    "ob_path = os.path.join(data_dir, 'Timeslices WFM Open Beam')\n",
    "instrument_file = os.path.join(experiment_dir, 'IDF', 'V20_Definition_GP2.xml')\n",
    "\n",
    "# Ensure Mantid isn't holding onto objects if the user re-runs the benchmark\n",
    "AnalysisDataService.clear()\n",
    "\n",
    "# Load X values from the TOF file\n",
    "def load_scipp_samples():\n",
    "    ds = sc.Dataset()\n",
    "    ds.coords[Dim.Tof] = sc.Variable([Dim.Tof], unit=sc.units.us, values=read_x_values(tofs_path))\n",
    "    ds.coords[Dim.Tof] *= 1e3\n",
    "    ds[\"sample\"] = tiffs_to_variable(sample_path)\n",
    "    ds[\"reference\"] = tiffs_to_variable(ob_path)\n",
    "    return ds\n",
    "\n",
    "def load_mantid_samples():\n",
    "    tofs = mantid_x_values(tofs_path)\n",
    "    mantid_sample = mantid_tiffs_to_workspace(sample_path, tofs, \"sample\")\n",
    "    mantid_reference = mantid_tiffs_to_workspace(ob_path, tofs, \"reference\")\n",
    "\n",
    "    mantid_sample = ScaleX(mantid_sample, 1e3, Operation='Multiply')\n",
    "    mantid_reference = ScaleX(mantid_reference, 1e3, Operation='Multiply')\n",
    "\n",
    "    # Note were missing a Scale(pulse_number) where pulse_number is 1/nPulses\n",
    "    return mantid_sample, mantid_reference\n",
    "\n",
    "# Prime IO cache - This is intentionally untimed, we use scipp to avoid having to clear the ADS in Mantid\n",
    "print(\"Priming IO cache\")\n",
    "load_scipp_samples()\n",
    "print(\"\\n---- IO Primed, lets benchmark -----\")\n",
    "\n",
    "ds = bench_scipp_func(load_scipp_samples)\n",
    "result = bench_mantid_func(load_mantid_samples)\n",
    "if result:\n",
    "    mantid_sample, mantid_reference = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_scipp():\n",
    "    ds.coords[Dim.Spectrum] = sc.Variable([Dim.Spectrum], values=np.arange(ds[\"sample\"].shape[1]))\n",
    "    stitched = sc.Dataset(coords={Dim.Tof: sc.Variable([Dim.Tof], values=np.arange(*rebin_parameters, dtype=np.float64))})\n",
    "\n",
    "    stitched[\"sample\"] = stitch(ds[\"sample\"], frame_parameters, rebin_parameters)\n",
    "    stitched[\"reference\"] = stitch(ds[\"reference\"], frame_parameters, rebin_parameters)\n",
    "    return stitched\n",
    "\n",
    "def stitch_mantid():\n",
    "    processor = wfm_stitching.WFMProcessor(mantid_frame_parameters, frame_shifts)\n",
    "    sample_stitched = processor.process(mantid_sample, instrument_file, mantid_rebin_parameters, scale=1, delete_temporary_workspaces=True)\n",
    "    reference_stitched = processor.process(mantid_reference, instrument_file, mantid_rebin_parameters, scale=1, delete_temporary_workspaces=True)\n",
    "    return sample_stitched, reference_stitched\n",
    "\n",
    "stitched = bench_scipp_func(stitch_scipp)\n",
    "result = bench_mantid_func(stitch_mantid)\n",
    "if result:\n",
    "    mantid_stitched_sample, mantid_stitched_reference = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_scipp():\n",
    "    stitched[\"normalized\"] = stitched[\"sample\"] / stitched[\"reference\"]\n",
    "    replacement=sc.Variable(value=0.0, variance=0.0)\n",
    "    kwargs = {\"nan\" : replacement, \"posinf\" : replacement, \"neginf\" : replacement}\n",
    "    sc.nan_to_num(stitched[\"normalized\"].data, out=stitched[\"normalized\"].data, **kwargs)\n",
    "    return stitched\n",
    "\n",
    "def normalize_mantid():\n",
    "    normalized_sample = Divide(mantid_stitched_sample, mantid_stitched_reference)\n",
    "    normalized_sample = ReplaceSpecialValues(normalized_sample, NaNValue=0, InfinityValue=0)\n",
    "    return normalized_sample\n",
    "\n",
    "stitched = bench_scipp_func(normalize_scipp)\n",
    "normalized_mantid = bench_mantid_func(normalize_mantid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scipp_group_detectors():\n",
    "    stitched.coords[\"detector_mapping\"] = make_detector_groups(324, 324, nx_target, ny_target)\n",
    "    grouped = sc.groupby(stitched[\"normalized\"], \"detector_mapping\")\n",
    "    return grouped\n",
    "\n",
    "def mantid_group_detectors():\n",
    "    mapping_file = os.path.join(data_dir, \"mantid_mapping_file.txt\")\n",
    "    mapping_file = mantid_make_map_file(destination=mapping_file, nx_original=324,\n",
    "                                        ny_original=324, nx_target=nx_target, ny_target=ny_target, start_spectrum_id=1)\n",
    "    grouped = GroupDetectors(normalized_mantid, MapFile=mapping_file)\n",
    "    return grouped\n",
    "\n",
    "grouped_unsummed = bench_scipp_func(scipp_group_detectors)\n",
    "grouped_mantid = bench_mantid_func(mantid_group_detectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scipp_sum_spectra():\n",
    "    grouped = sc.Dataset()\n",
    "    grouped[\"normalized_grpd\"] = grouped_unsummed.sum(Dim.Spectrum)\n",
    "    return grouped\n",
    "\n",
    "def mantid_sum_spectra():\n",
    "    summed = SumSpectra(grouped_mantid)\n",
    "    return summed\n",
    "\n",
    "summed = bench_scipp_func(scipp_sum_spectra)\n",
    "summed_mantid = bench_mantid_func(mantid_sum_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scipp_convert_units():\n",
    "    # Adds the component info needed for converting units\n",
    "    sc.compat.mantid.load_component_info(stitched, instrument_file)\n",
    "    summed.coords[\"source_position\"] = stitched.coords[\"source_position\"]\n",
    "    summed.coords[\"sample_position\"] = stitched.coords[\"sample_position\"]\n",
    "\n",
    "    # makes the position a DataConstProxy otherwise groupby won't take it\n",
    "    stitched[\"position\"] = stitched.coords[\"position\"]\n",
    "    dm1d = sc.groupby(stitched[\"position\"], \"detector_mapping\")\n",
    "    position = dm1d.mean(Dim.Spectrum)\n",
    "\n",
    "    # can't do stitched.labels[\"position\"] = position because Labels won't take a DataArray\n",
    "    # also can't do stitched.labels[\"position\"] = sc.Variable(position) because then sc.convert\n",
    "    # thinks stitched.labels[\"position\"] is dimensionless (as it's actually still a DataArray)\n",
    "\n",
    "    pos = np.zeros((position.shape[0], 3))\n",
    "    for i, val in enumerate(position.values):\n",
    "        pos[i, :] = val\n",
    "\n",
    "    # finally add it back!\n",
    "    summed.coords[\"position\"] = sc.Variable(position.dims, pos, unit=sc.units.m, dtype=position.dtype)\n",
    "    summed[\"normalized_wl\"] = sc.neutron.convert(summed[\"normalized_grpd\"], Dim.Tof, Dim.Wavelength)\n",
    "    return summed\n",
    "\n",
    "def mantid_convert_units():\n",
    "   wav_ws = ConvertUnits(summed_mantid, Target='Wavelength')\n",
    "   return wav_ws\n",
    "\n",
    "wavelength = bench_scipp_func(scipp_convert_units)\n",
    "wavelength_mantid = bench_mantid_func(mantid_convert_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Benchmark completed\")\n",
    "print(f\"Scipp total time: {totals.scipp_total_time}\")\n",
    "print(f\"Mantid total time: {totals.mantid_total_time}\")\n",
    "\n",
    "# The below is not benchmarked as it uses Mantid to do the processing anyway\n",
    "\n",
    "# x_coords = wavelength[\"normalized_wl\"].coords[\"wavelength\"]\n",
    "# x_dim = wavelength[\"normalized_wl\"].dims[0]\n",
    "# x = x_coords.values\n",
    "#\n",
    "# # Mantid expects the data in a different shape\n",
    "# # which is spectrum as outer-most dimension.\n",
    "# y = np.transpose(wavelength[\"normalized_wl\"].values)\n",
    "# e = np.transpose(wavelength[\"normalized_wl\"].variances)\n",
    "#\n",
    "# ws = sc.compat.mantid.to_workspace_2d(x, y, e, str(x_dim), instrument_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to save the workspace uncomment this line\n",
    "# SaveNexusESS(ws, \"scipp_normalized_wl.nxs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fit_ds = sc.compat.mantid.fit(ws,\n",
    "#                     function='name=LinearBackground,A0=5000,A1=0;name=UserFunction,Formula=h*erfc(a*(x-x0)),h=5000,a=-0.5,x0=4',\n",
    "#                     workspace_index=2, start_x=3.6, end_x=4.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}