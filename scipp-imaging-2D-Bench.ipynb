{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to start\n",
    "\n",
    "Read instructions from the start of the `scipp-imaging-2D` notebook, and try running it. If you can run it without any issues, then you shouldn't have any issues running this notebook.\n",
    "\n",
    "This notebook is not intended to produce any data output, and it should only be ran to see timing results on different operations. Previous benchmarks have been recorded here: https://github.com/scipp/scipp/issues/812"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created by Owen Arnold (optional e-mail) on 2018-09-19\n",
    "# last modified by Peter M. Kadletz (peter.kadletz@esss.se) on 2018-11-12\n",
    "import fabio\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import scipp as sc\n",
    "import numpy as np\n",
    "from scipp import Dim\n",
    "\n",
    "from mantid.simpleapi import *\n",
    "from mantid.api import AlgorithmManager\n",
    "\n",
    "from wfm_stitching import WFMProcessor\n",
    "\n",
    "DTYPE = np.float64\n",
    "\n",
    "# defining grouping of 2D detector pixels\n",
    "grouping_number = 12\n",
    "nx_target = grouping_number\n",
    "ny_target = grouping_number\n",
    "\n",
    "# Number of acquired pulses per measurement\n",
    "pulse_nr_reference = 1.0 / 770956\n",
    "pulse_nr_sample = 1.0 / 1280381\n",
    "pulse_nr_sample_elastic = 1.0 / 2416839\n",
    "pulse_nr_plastic = 1.0 / 2614343\n",
    "\n",
    "# let's get the process started:\n",
    "experiment_dir = \"/home/dtasev/dev/scipp_imaging/RAL_Mantid_Sep2018/\"\n",
    "\n",
    "tofs_path = os.path.join(experiment_dir, 'data_GP2', 'metadata', 'GP2_Stress_time_values.txt')\n",
    "sample_path = os.path.join(experiment_dir, 'data_GP2', 'Stress Experiments', '2) R825')\n",
    "sample_elastic_path = os.path.join(experiment_dir, 'data_GP2', 'Stress Experiments', '3) R825 600 Mpa')\n",
    "ob_path = os.path.join(experiment_dir, 'data_GP2', 'Stress Experiments', '1) R825 Open Beam')\n",
    "\n",
    "# These use the range notation of [start, stop, step]\n",
    "# for R825\n",
    "frame_parameters = [(15450,22942,64),\n",
    "                    (24800,32052,64),\n",
    "                    (33791,40084,64),\n",
    "                    (41763,47457,64),\n",
    "                    (49315,54500,64),\n",
    "                    (56500,58360,64)]\n",
    "\n",
    "# for BBC\n",
    "# frame_parameters = [(16e3, 23e3, 64),\n",
    "#                     (24.5e3, 32.5e3, 64),\n",
    "#                     (33.5e3, 40.2e3, 64),\n",
    "#                     (41.7e3, 47.73e3, 64),\n",
    "#                     (49.29e3, 55.11e3, 64),\n",
    "#                     (56.57e3, 60e3, 64)]\n",
    "\n",
    "pulse_nr_reference = 1.0 / 770956\n",
    "pulse_nr_sample = 1.0 / 1280381\n",
    "pulse_nr_sample_elastic = 1.0 / 2416839\n",
    "pulse_nr_plastic = 1.0 / 2614343\n",
    "\n",
    "# Two options availabe for frame shift increments: 1) Robins Calibrated Values 2) Owens Calculated Values.\n",
    "\n",
    "frame_shift_increments = [-6630.0, -2420.0, -2253.0, -2095.0, -1946.0, -1810.0]\n",
    "# frame_shift_increments = [-6630,-2423,-2252,-2058,-1949,-1576]\n",
    "frame_shifts = [sum(frame_shift_increments[:i + 1]) for i in range(len(frame_shift_increments))]\n",
    "# rebin region reduced to cut off frames that contain no data\n",
    "rebin_parameters = (8500, 43000, 64)\n",
    "# instrument_filename = os.path.join(experiment_dir, 'IDF', 'V20_Definition_GP2.xml')\n",
    "# accumulated_pulses_sample = 225000\n",
    "# accumulated_pulses_reference = 250000\n",
    "# scaling_factor = float(accumulated_pulses_reference) / float(accumulated_pulses_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "\n",
    "def read_x_values(tof_file):\n",
    "    \"\"\"\n",
    "    Reads the TOF values from the CSV into a list\n",
    "    \"\"\"\n",
    "    tof_values = list()\n",
    "    with open(tof_file) as fh:\n",
    "        csv_reader = csv.reader(fh, delimiter='\\t')\n",
    "        next(csv_reader, None)  # skip header\n",
    "        for row in csv_reader:\n",
    "            tof_values.append(float(row[1]))\n",
    "    return tof_values\n",
    "\n",
    "\n",
    "def _load_tiffs(tiff_dir):\n",
    "    if not os.path.isdir(tiff_dir):\n",
    "        raise RuntimeError(tiff_dir + \" is not directory\")\n",
    "    stack = []\n",
    "    path_length = len(tiff_dir) + 1\n",
    "    filenames = sorted(glob.glob(tiff_dir + \"/*.tiff\"))\n",
    "    nfiles = len(filenames)\n",
    "    count = 0\n",
    "    print(f\"Loading {nfiles} files from '{tiff_dir}'\")\n",
    "    for filename in filenames:\n",
    "        count += 1\n",
    "        print('\\r{0}: Image {1}, of {2}'.format(filename[path_length:], count, nfiles), end=\"\")\n",
    "        img = fabio.open(os.path.join(tiff_dir, filename))\n",
    "        stack.append(np.flipud(img.data))\n",
    "\n",
    "    return np.array(stack)\n",
    "\n",
    "def tiffs_to_variable(tiff_dir):\n",
    "    \"\"\"\n",
    "    Loads all tiff images from the directory into a scipp Variable.\n",
    "    \"\"\"\n",
    "    stack = _load_tiffs(tiff_dir)\n",
    "    return sc.Variable([Dim.Tof, Dim.Spectrum], \n",
    "                       values=stack.astype(DTYPE).reshape(\n",
    "                           stack.shape[0], stack.shape[1]*stack.shape[2]))\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "def stitch(data_array, frame_parameters, rebin_parameters):\n",
    "    \"\"\"\n",
    "    Stitches the 5 different frames data.\n",
    "    \n",
    "    It crops out each frame, then shifts it so that all frames align,\n",
    "    and then rebins to the common bins used for all frames.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "\n",
    "    rebin_params = sc.Variable([Dim.Tof], values=np.arange(*rebin_parameters, dtype=DTYPE))\n",
    "    \n",
    "    for i, (slice_bins, shift_parameter) in enumerate(zip(frame_parameters, frame_shifts)):\n",
    "        bins = sc.Variable([Dim.Tof], values=np.arange(*slice_bins, dtype=DTYPE))\n",
    "        # Rebins the whole data to crop it to frame bins\n",
    "        rebinned = sc.rebin(data_array, Dim.Tof, bins)\n",
    "        # Shift the frame backwards to make all frames overlap\n",
    "        rebinned.coords[Dim.Tof] += shift_parameter\n",
    "        # Rebin to overarching coordinates so that the frame coordinates align\n",
    "        rebinned = sc.rebin(rebinned, Dim.Tof, rebin_params)\n",
    "\n",
    "        frames.append(rebinned)\n",
    "\n",
    "    for f in frames[1:]:\n",
    "        frames[0] += f\n",
    "\n",
    "    return frames[0]\n",
    "\n",
    "\n",
    "def remove_special_values(values):\n",
    "    np.nan_to_num(values, copy=False)\n",
    "    values[values == sys.float_info.max] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stitch_faster(data_array, frame_parameters, rebin_parameters):\n",
    "#     \"\"\"\n",
    "#     TODO: unfinished function that replaces Rebins with slices, which should be a lot faster\n",
    "#     The idea is: instead of rebinning to crop the data, just slice it, and sum that. \n",
    "#     then either continue like that or do a single rebin at the end to produce the same\n",
    "#     bins as the current operation does (i.e. rebin to 8300, 43000, 64)\n",
    "#\n",
    "#\n",
    "#     Stitches the 5 different frames data.\n",
    "    \n",
    "#     It crops out each frame, then shifts it so that all frames align,\n",
    "#     and then rebins to the common bins used for all frames.\n",
    "#     \"\"\"\n",
    "#     frames = []\n",
    "\n",
    "#     rebin_params = sc.Variable([Dim.Tof], values=np.arange(*rebin_parameters, dtype=np.float64))\n",
    "\n",
    "#     # The bin range will be the from start of the first frame to the end of the end of the last one\n",
    "#     # using the same step as the frame parameters\n",
    "#     outbins = np.arange(frame_parameters[0][0], frame_parameters[-1][1], frame_parameters[0][2], \n",
    "#                                                                 dtype=np.float64)\n",
    "#     out = sc.DataArray(sc.Variable([Dim.Tof, Dim.Spectrum], shape=[outbins.shape[0], data_array.shape[1]]),\n",
    "#                       coords={\n",
    "#                           Dim.Tof: sc.Variable([Dim.Tof], \n",
    "#                                                values=outbins, \n",
    "#                                                unit=data_array.coords[Dim.Tof].unit)})\n",
    "    \n",
    "#     last = 0\n",
    "#     for i, (slice_bins, shift_parameter) in enumerate(zip(frame_parameters, frame_shifts)):\n",
    "#         print(slice_bins)\n",
    "#         start_bin_idx = np.where(rebin_params.values > slice_bins[0])[0][0]\n",
    "#         end_bin_idx = np.where(rebin_params.values > slice_bins[1])[0][0]\n",
    "#         print(start_bin_idx, end_bin_idx)\n",
    "#         # Rebin to overarching coordinates so that the frame coordinates align\n",
    "        \n",
    "#         begin = last\n",
    "#         end = (slice_bins[1] - slice_bins[0]) // slice_bins[2] # indices from width of the frame\n",
    "#         last = end\n",
    "\n",
    "#         # TODO figure out why \n",
    "#         # Shift the X coord and set them for the frame\n",
    "#         out.coords[Dim.Tof, begin:end] = data_array[Dim.Tof, start_bin_idx:end_bin_idx].coords[Dim.Tof] + shift_parameter * sc.units.us\n",
    "#         # Slice the data for this frame\n",
    "#         out[Dim.Tof, begin:end] = data_array[Dim.Tof, start_bin_idx:end_bin_idx]\n",
    "\n",
    "#     # TODO sum & maybe rebin\n",
    "#     return frames[0]\n",
    "\n",
    "# stitch111(ds[\"reference\"], frame_parameters, rebin_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure the data (Tof, Row, Column)\n",
    "ds = sc.Dataset()\n",
    "\n",
    "ds.coords[Dim.Tof] = sc.Variable([Dim.Tof], unit=sc.units.us, values=read_x_values(tofs_path), dtype=DTYPE)\n",
    "%time ds.coords[Dim.Tof] *= 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL: Scaling Data\n",
    "\n",
    "# Load the images into the dataset\n",
    "# And scale each one\n",
    "ds[\"reference\"] = tiffs_to_variable(ob_path)\n",
    "%time ds[\"reference\"] *= pulse_nr_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"sample\"] = tiffs_to_variable(sample_path)\n",
    "%time ds[\"sample\"] *= pulse_nr_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"sample_elastic\"] = tiffs_to_variable(sample_elastic_path)\n",
    "%time ds[\"sample_elastic\"] *= pulse_nr_sample_elastic\n",
    "\n",
    "ds.coords[Dim.Spectrum] = sc.Variable([Dim.Spectrum], values=np.arange(ds[\"sample\"].shape[1], dtype=DTYPE))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched = sc.Dataset(coords={Dim.Tof: sc.Variable([Dim.Tof], values=np.arange(*rebin_parameters, dtype=DTYPE))})\n",
    "\n",
    "# LABEL: Stitching\n",
    "\n",
    "%time stitched[\"sample\"] = stitch(ds[\"sample\"], frame_parameters, rebin_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched[\"reference\"] = stitch(ds[\"reference\"], frame_parameters, rebin_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time stitched[\"sample_elastic\"] = stitch(ds[\"sample_elastic\"], frame_parameters, rebin_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL: Normalization\n",
    "%time stitched[\"normalized\"] = stitched[\"sample\"] / stitched[\"reference\"]\n",
    "\n",
    "%time remove_special_values(stitched[\"normalized\"].values)\n",
    "np.max(stitched[\"normalized\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched[\"normalized_elastic\"] = stitched[\"sample_elastic\"] / stitched[\"reference\"]\n",
    "remove_special_values(stitched[\"normalized_elastic\"].values)\n",
    "np.max(stitched[\"normalized_elastic\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL: Summing spectra\n",
    "%time stitched[\"normalized_summed\"] = sc.sum(stitched[\"normalized\"], Dim.Spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched[\"normalized_elastic_summed\"] = sc.sum(stitched[\"normalized_elastic\"], Dim.Spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_number = 12\n",
    "nx_target = grouping_number\n",
    "ny_target = grouping_number\n",
    "\n",
    "def make_map_file(nx_original, ny_original, nx_target, ny_target):\n",
    "    element_width_x = nx_original // nx_target\n",
    "    element_width_y = ny_original // ny_target\n",
    "    \n",
    "    # To contain our new spectra mappings\n",
    "    grid = np.zeros((nx_original, ny_original), dtype=DTYPE)\n",
    "\n",
    "    for i in range(0, nx_target):\n",
    "        for j in range(0, ny_target):\n",
    "            x_start = i * element_width_x\n",
    "            x_end = (i + 1) * element_width_x\n",
    "            \n",
    "            y_start = j * element_width_y\n",
    "            y_end = (j + 1) * element_width_y\n",
    "\n",
    "            vals = np.full((element_width_x, element_width_y), i + j * nx_target, dtype=DTYPE)\n",
    "            grid[x_start:x_end, y_start:y_end] = vals\n",
    "    \n",
    "    return sc.Variable([Dim.Spectrum], values=grid.ravel())\n",
    "\n",
    "\n",
    "stitched.labels[\"detector_mapping\"] = make_map_file(324, 324, nx_target, ny_target)\n",
    "stitched.labels[\"detector_mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL: Group detectors\n",
    "dm1d = sc.groupby(stitched[\"normalized\"], \"detector_mapping\", Dim.Row)\n",
    "%time stitched[\"normalized_grpd\"] = dm1d.sum(Dim.Spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(pos):\n",
    "    return [pos.X(), pos.Y(), pos.Z()]\n",
    "\n",
    "def make_component_info(ws):\n",
    "    sourcePos = ws.componentInfo().sourcePosition()\n",
    "    samplePos = ws.componentInfo().samplePosition()\n",
    "\n",
    "    def as_var(pos):\n",
    "        return sc.Variable(value=np.array(get_pos(pos)),\n",
    "                           dtype=sc.dtype.vector_3_float64,\n",
    "                           unit=sc.units.m)\n",
    "\n",
    "    return as_var(sourcePos), as_var(samplePos)\n",
    "\n",
    "def init_pos(ws):\n",
    "    nHist = ws.getNumberHistograms()\n",
    "    pos = np.zeros([nHist, 3])\n",
    "\n",
    "    spec_info = ws.spectrumInfo()\n",
    "    for i in range(nHist):\n",
    "        if spec_info.hasDetectors(i):\n",
    "            p = spec_info.position(i)\n",
    "            pos[i, :] = [p.X(), p.Y(), p.Z()]\n",
    "        else:\n",
    "            pos[i, :] = [np.nan, np.nan, np.nan]\n",
    "    return sc.Variable([sc.Dim.Spectrum],\n",
    "                       values=pos,\n",
    "                       unit=sc.units.m,\n",
    "                       dtype=sc.dtype.vector_3_float64)\n",
    "\n",
    "def load_component_info_from_instrument_file(ds, file):\n",
    "    try:\n",
    "        import mantid.simpleapi as mantid\n",
    "        from mantid.api import Workspace\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"Mantid Python API was not found, please install Mantid framework \"\n",
    "            \"as detailed in the installation instructions (https://scipp.\"\n",
    "            \"readthedocs.io/en/latest/getting-started/installation.html)\")\n",
    "    ws = mantid.Load(file)\n",
    "    \n",
    "    source_pos, sample_pos = make_component_info(ws)\n",
    "    \n",
    "    ds.labels[\"source_position\"] = source_pos\n",
    "    ds.labels[\"sample_position\"] = sample_pos\n",
    "    ds.labels[\"position\"] = init_pos(ws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_component_info_from_instrument_file(stitched, '/home/dtasev/dev/scipp_imaging/RAL_Mantid_Sep2018/IDF/V20_Definition_GP2.xml')\n",
    "stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes the position a DataConstProxy otherwise groupby won't take it\n",
    "stitched[\"position\"] = stitched.labels[\"position\"]\n",
    "dm1d = sc.groupby(stitched[\"position\"], \"detector_mapping\", Dim.Row)\n",
    "position = dm1d.mean(Dim.Spectrum)\n",
    "\n",
    "# can't do stitched.labels[\"position\"] = position because Labels won't take a DataArray\n",
    "# also can't do stitched.labels[\"position\"] = sc.Variable(position) because then sc.convert \n",
    "# thinks stitched.labels[\"position\"] is dimensionless (as it's actually still a DataArray)\n",
    "\n",
    "pos = np.zeros((position.shape[0], 3))\n",
    "for i, val in enumerate(position.values):\n",
    "    pos[i, :] = val\n",
    "\n",
    "# finally add it back!\n",
    "stitched.labels[\"position\"] = sc.Variable(position.dims, pos, unit=sc.units.m, dtype=position.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL: Convert Units\n",
    "%time stitched[\"normalized_wl\"] = sc.neutron.convert(stitched[\"normalized_grpd\"], Dim.Tof, Dim.Wavelength)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scipp-mantid] *",
   "language": "python",
   "name": "conda-env-scipp-mantid-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
